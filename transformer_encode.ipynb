{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "W05UQKZ4mK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "5EuSlc7r5x"
      },
      "source": [
        "class TokenAndPositionEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, max_lengths, device = 'cpu'):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(\n",
        "            num_embeddings = vocab_size, # Corpus size or dictionary size\n",
        "            embedding_dim = embed_dim # Embedding dimension for each word\n",
        "        )\n",
        "        self.pos_embedding = nn.Embedding(\n",
        "            num_embeddings = max_lengths, # Maximum length of sequential\n",
        "            embedding_dim = embed_dim # Embedding dimension for each position\n",
        "        )\n",
        "        \n",
        "    def forward(self, output):\n",
        "        N, seq_length = output.size() # N is batch size, seq_length is sequence length\n",
        "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device) # N x seq_length\n",
        "        output1 = self.word_embedding(output) # N x seq_length x embed_dim\n",
        "        output2 = self.pos_embedding(positions) # N x seq_length x embed_dim\n",
        "        return output1 + output2\n",
        "        "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "NAtul6jfUD"
      },
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(\n",
        "            embed_dim = embed_dim,\n",
        "            num_heads = num_heads,\n",
        "            batch_first = True\n",
        "        )\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(in_features = embed_dim, # Input dimension\n",
        "                      out_features = ff_dim, # Feed forward dimension\n",
        "                      bias = True # Bias term \n",
        "                        ),\n",
        "            nn.ReLU(), # activation Function\n",
        "            nn.Linear(in_features = ff_dim , # Input dimension\n",
        "                      out_features = embed_dim, # Feed forward dimension\n",
        "                      bias = True # Bias term\n",
        "                    )\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(normalized_shape = embed_dim, eps = 1e-6)\n",
        "        self.norm2 = nn.LayerNorm(normalized_shape = embed_dim, eps = 1e-6)\n",
        "        self.dropout1 = nn.Dropout(p = dropout)\n",
        "        self.dropout2 = nn.Dropout(p = dropout)\n",
        "        \n",
        "    def forward(self, query, key, value):\n",
        "        attn_output, _ = self.attn(query, key, value)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.norm1(query + attn_output) # we must add the residual connection\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.norm2(out1 + ffn_output) # we must add the residual connection\n",
        "        return out2"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "PwiQILORlX"
      },
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, src_vocab_size, embed_dim, max_lengths, num_layers, num_heads, ff_dim, dropout = 0.1, device = 'cpu'):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.embedding = TokenAndPositionEmbedding(\n",
        "            src_vocab_size, embed_dim, max_lengths, device\n",
        "        )\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerEncoderBlock(\n",
        "                    embed_dim, num_heads, ff_dim, dropout\n",
        "                ) for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, output):\n",
        "        output = self.embedding(output)\n",
        "        for layer in self.layers:\n",
        "            output = layer(output, output, output)\n",
        "        return output"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "bIpHo4E0S5"
      },
      "source": [
        "batch_size = 32\n",
        "max_lengths = 100\n",
        "src_vocab_size = 1000\n",
        "embed_dim = 128\n",
        "ff_dim = 1024\n",
        "num_heads = 8\n",
        "num_layers = 6"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "QsjaLe3l4R"
      },
      "source": [
        "input = torch.randint(\n",
        "    high = 2,\n",
        "    size = (batch_size, max_lengths), # Batch size x Sequence length\n",
        "    dtype = torch.int64\n",
        ")\n",
        "model = TransformerEncoder(src_vocab_size, embed_dim, max_lengths, num_layers, num_heads, ff_dim, dropout)\n",
        "output = model(input)\n",
        "output.shape # Batch size x Sequence length x Embedding dimension"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "torch.Size([32, 100, 128])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}